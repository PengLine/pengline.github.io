<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>LangChain 框架功能详解和使用案例 | 余一叶知秋尽</title><meta name="author" content="余一叶知秋尽"><meta name="copyright" content="余一叶知秋尽"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="开源框架 LangChain，旨在简化基于大语言模型构建应用程序的过程。集成了记忆机制、工具调用和智能决策等。">
<meta property="og:type" content="article">
<meta property="og:title" content="LangChain 框架功能详解和使用案例">
<meta property="og:url" content="https://pengline.github.io/2025/11/0c17e5dc04ae4994b411db081a7c82d6/index.html">
<meta property="og:site_name" content="余一叶知秋尽">
<meta property="og:description" content="开源框架 LangChain，旨在简化基于大语言模型构建应用程序的过程。集成了记忆机制、工具调用和智能决策等。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://pengline.github.io/img/essay/small162627wjXnR1759047987.webp">
<meta property="article:published_time" content="2025-11-05T16:00:00.000Z">
<meta property="article:modified_time" content="2025-11-24T03:22:32.428Z">
<meta property="article:author" content="余一叶知秋尽">
<meta property="article:tag" content="LangChain框架">
<meta property="article:tag" content="LangChain状态记忆">
<meta property="article:tag" content="LangChain智能决策">
<meta property="article:tag" content="LangChain提示工程">
<meta property="article:tag" content="LangChain工具调用">
<meta property="article:tag" content="LangChain模型管理">
<meta property="article:tag" content="LangChain链">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://pengline.github.io/img/essay/small162627wjXnR1759047987.webp"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "LangChain 框架功能详解和使用案例",
  "url": "https://pengline.github.io/2025/11/0c17e5dc04ae4994b411db081a7c82d6/",
  "image": "https://pengline.github.io/img/essay/small162627wjXnR1759047987.webp",
  "datePublished": "2025-11-05T16:00:00.000Z",
  "dateModified": "2025-11-24T03:22:32.428Z",
  "author": [
    {
      "@type": "Person",
      "name": "余一叶知秋尽",
      "url": "https://pengline.github.io"
    }
  ]
}</script><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="https://pengline.github.io/2025/11/0c17e5dc04ae4994b411db081a7c82d6/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":true,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":30,"languages":{"author":"作者: 余一叶知秋尽","link":"链接: ","source":"来源: 余一叶知秋尽","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'LangChain 框架功能详解和使用案例',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><link rel="stylesheet" href="/css/font.css"><svg aria-hidden="true" style="position:absolute; overflow:hidden; width:0; height:0"><symbol id="icon-sun" viewBox="0 0 1024 1024"><path d="M960 512l-128 128v192h-192l-128 128-128-128H192v-192l-128-128 128-128V192h192l128-128 128 128h192v192z" fill="#FFD878" p-id="8420"></path><path d="M736 512a224 224 0 1 0-448 0 224 224 0 1 0 448 0z" fill="#FFE4A9" p-id="8421"></path><path d="M512 109.248L626.752 224H800v173.248L914.752 512 800 626.752V800h-173.248L512 914.752 397.248 800H224v-173.248L109.248 512 224 397.248V224h173.248L512 109.248M512 64l-128 128H192v192l-128 128 128 128v192h192l128 128 128-128h192v-192l128-128-128-128V192h-192l-128-128z" fill="#4D5152" p-id="8422"></path><path d="M512 320c105.888 0 192 86.112 192 192s-86.112 192-192 192-192-86.112-192-192 86.112-192 192-192m0-32a224 224 0 1 0 0 448 224 224 0 0 0 0-448z" fill="#4D5152" p-id="8423"></path></symbol><symbol id="icon-moon" viewBox="0 0 1024 1024"><path d="M611.370667 167.082667a445.013333 445.013333 0 0 1-38.4 161.834666 477.824 477.824 0 0 1-244.736 244.394667 445.141333 445.141333 0 0 1-161.109334 38.058667 85.077333 85.077333 0 0 0-65.066666 135.722666A462.08 462.08 0 1 0 747.093333 102.058667a85.077333 85.077333 0 0 0-135.722666 65.024z" fill="#FFB531" p-id="11345"></path><path d="M329.728 274.133333l35.157333-35.157333a21.333333 21.333333 0 1 0-30.165333-30.165333l-35.157333 35.157333-35.114667-35.157333a21.333333 21.333333 0 0 0-30.165333 30.165333l35.114666 35.157333-35.114666 35.157334a21.333333 21.333333 0 1 0 30.165333 30.165333l35.114667-35.157333 35.157333 35.157333a21.333333 21.333333 0 1 0 30.165333-30.165333z" fill="#030835" p-id="11346"></path></symbol></svg><meta name="generator" content="Hexo 7.3.0"><link rel="alternate" href="/atom.xml" title="余一叶知秋尽" type="application/atom+xml">
</head><body><div id="web_bg" style="background: LightGray;"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="/img/butterfly-icon.webp" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">52</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">234</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">41</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list-ul"></i><span> 归档</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类别</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签集</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-outdent"></i><span> AI</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ai/aigc/"><i class="fa-fw fas fa-cubes"></i><span> AIGC 创意平台</span></a></li><li><a class="site-page child" href="/ai/agent/medical/"><i class="fa-fw fas fa-medkit"></i><span> 医疗问答Agent</span></a></li><li><a class="site-page child" href="https://github.com/HengLine/ai-stocks-agent"><i class="fa-fw fas fa-line-chart"></i><span> 股票分析Agent</span></a></li><li><a class="site-page child" href="/ai/agent/video/"><i class="fa-fw fas fa-cut"></i><span> 视频混剪Agent</span></a></li><li><a class="site-page child" href="https://github.com/HengLine/video-shot-agent"><i class="fa-fw fas fa-file-video"></i><span> 剧本分镜Agent</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-cogs"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tools/json/"><i class="fa-fw fas fa-cog"></i><span> JSON 转换工具集</span></a></li><li><a class="site-page child" href="/tools/diagrams/mermaid"><i class="fa-fw fas fa-pie-chart"></i><span> 在线绘制 UML 图</span></a></li><li><a class="site-page child" href="/tools/image/compressor/"><i class="fa-fw fas fa-image"></i><span> 图像批量压缩大小</span></a></li><li><a class="site-page child" href="/tools/image/watermark/"><i class="fa-fw fas fa-image"></i><span> 图像批量添加水印</span></a></li><li><a class="site-page child" href="/tools/image/convert/"><i class="fa-fw fas fa-image"></i><span> 图像格式编码转换</span></a></li><li><a class="site-page child" href="/tools/video/cropping/"><i class="fa-fw fas fa-cut"></i><span> 视频时长范围裁剪</span></a></li><li><a class="site-page child" href="/tools/video/watermark/"><i class="fa-fw fas fa-video"></i><span> 视频加水印马赛克</span></a></li><li><a class="site-page child" href="/tools/download/"><i class="fa-fw fas fa-download"></i><span> 批量下载视频图片</span></a></li><li><a class="site-page child" href="/tools/docu/watermark/"><i class="fa-fw fas fa-file-pdf"></i><span> PDF 文档添加水印</span></a></li><li><a class="site-page child" href="/tools/docu/signature"><i class="fa-fw fas fa-file"></i><span> 文档在线手写签名</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-pencil-square"></i><span> 文学</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/literature/poems"><i class="fa-fw fas fa-align-center"></i><span> 三行诗集</span></a></li><li><a class="site-page child" href="/literature/classical"><i class="fa-fw fas fa-align-justify"></i><span> 诗词歌赋</span></a></li><li><a class="site-page child" href="/literature/modern"><i class="fa-fw fas fa-align-left"></i><span> 现代诗歌</span></a></li><li><a class="site-page child" href="/literature/journal"><i class="fa-fw fas fa-align-right"></i><span> 随心随笔</span></a></li><li><a class="site-page child" href="/literature/incomplete"><i class="fa-fw fas fa-columns"></i><span> 忘梦残句</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-commenting"></i><span> 交流</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-paper-plane"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url(/img/essay/small162627wjXnR1759047987.webp);"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><img class="site-icon" src= "/img/20241215205335173426721579192.webp" data-lazy-src="/img/logo.png" alt="Logo"><span class="site-name">余一叶知秋尽</span></a><a class="nav-page-title" href="/"><span class="site-name">LangChain 框架功能详解和使用案例</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list-ul"></i><span> 归档</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类别</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签集</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-outdent"></i><span> AI</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/ai/aigc/"><i class="fa-fw fas fa-cubes"></i><span> AIGC 创意平台</span></a></li><li><a class="site-page child" href="/ai/agent/medical/"><i class="fa-fw fas fa-medkit"></i><span> 医疗问答Agent</span></a></li><li><a class="site-page child" href="https://github.com/HengLine/ai-stocks-agent"><i class="fa-fw fas fa-line-chart"></i><span> 股票分析Agent</span></a></li><li><a class="site-page child" href="/ai/agent/video/"><i class="fa-fw fas fa-cut"></i><span> 视频混剪Agent</span></a></li><li><a class="site-page child" href="https://github.com/HengLine/video-shot-agent"><i class="fa-fw fas fa-file-video"></i><span> 剧本分镜Agent</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-cogs"></i><span> 工具</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/tools/json/"><i class="fa-fw fas fa-cog"></i><span> JSON 转换工具集</span></a></li><li><a class="site-page child" href="/tools/diagrams/mermaid"><i class="fa-fw fas fa-pie-chart"></i><span> 在线绘制 UML 图</span></a></li><li><a class="site-page child" href="/tools/image/compressor/"><i class="fa-fw fas fa-image"></i><span> 图像批量压缩大小</span></a></li><li><a class="site-page child" href="/tools/image/watermark/"><i class="fa-fw fas fa-image"></i><span> 图像批量添加水印</span></a></li><li><a class="site-page child" href="/tools/image/convert/"><i class="fa-fw fas fa-image"></i><span> 图像格式编码转换</span></a></li><li><a class="site-page child" href="/tools/video/cropping/"><i class="fa-fw fas fa-cut"></i><span> 视频时长范围裁剪</span></a></li><li><a class="site-page child" href="/tools/video/watermark/"><i class="fa-fw fas fa-video"></i><span> 视频加水印马赛克</span></a></li><li><a class="site-page child" href="/tools/download/"><i class="fa-fw fas fa-download"></i><span> 批量下载视频图片</span></a></li><li><a class="site-page child" href="/tools/docu/watermark/"><i class="fa-fw fas fa-file-pdf"></i><span> PDF 文档添加水印</span></a></li><li><a class="site-page child" href="/tools/docu/signature"><i class="fa-fw fas fa-file"></i><span> 文档在线手写签名</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-pencil-square"></i><span> 文学</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/literature/poems"><i class="fa-fw fas fa-align-center"></i><span> 三行诗集</span></a></li><li><a class="site-page child" href="/literature/classical"><i class="fa-fw fas fa-align-justify"></i><span> 诗词歌赋</span></a></li><li><a class="site-page child" href="/literature/modern"><i class="fa-fw fas fa-align-left"></i><span> 现代诗歌</span></a></li><li><a class="site-page child" href="/literature/journal"><i class="fa-fw fas fa-align-right"></i><span> 随心随笔</span></a></li><li><a class="site-page child" href="/literature/incomplete"><i class="fa-fw fas fa-columns"></i><span> 忘梦残句</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-commenting"></i><span> 交流</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/messageboard/"><i class="fa-fw fas fa-paper-plane"></i><span> 留言板</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于我</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">LangChain 框架功能详解和使用案例</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-11-05T16:00:00.000Z" title="发表于 2025-11-06 00:00:00">2025-11-06</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-11-24T03:22:32.428Z" title="更新于 2025-11-24 11:22:32">2025-11-24</time></span></div><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/">AI</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/AI/Agent/">Agent</a></span><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>LangChain 提供了一套模块化的工具和抽象，使开发者能够将 LLM 与外部数据源、记忆机制、工具调用和逻辑控制流结合起来，从而构建可扩展、可维护、具有上下文感知能力的智能应用，比如聊天机器人、问答系统、文档摘要器、自动化代理（Agents）等。</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>使用的 LangChain 组件</th>
</tr>
</thead>
<tbody>
<tr>
<td>智能客服</td>
<td>Memory + Chain + LLM</td>
</tr>
<tr>
<td>知识库问答</td>
<td>Retrieval + RAG + Vector DB</td>
</tr>
<tr>
<td>自动化办公助理</td>
<td>Agents + Tools（如 Gmail、Excel、API）</td>
</tr>
<tr>
<td>代码生成助手</td>
<td>LLM + Prompt + OutputParser</td>
</tr>
<tr>
<td>多轮推理任务</td>
<td>Agents + Plan-and-execute</td>
</tr>
</tbody>
</table>
<p>LangChain 的架构围绕以下几个核心概念展开：</p>
<h2 id="模型管理（LLM）">模型管理（LLM）</h2>
<p>支持多种 LLM 提供商（如 OpenAI、qWen、Hugging Face、Google、Ollama 等）。</p>
<p>提供统一接口调用不同模型：</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p><strong>LLM（文本生成）</strong>：<code>ChatOpenAI</code>, <code>ChatTongyi</code>（Qwen）, <code>ChatOllama</code>, <code>ChatAnthropic</code></p>
</li>
<li class="lvl-2">
<p><strong>Embedding（向量化）</strong>：<code>OpenAIEmbeddings</code>, <code>DashScopeEmbeddings</code>（Qwen）, <code>OllamaEmbeddings</code></p>
</li>
<li class="lvl-2">
<p><strong>多模态模型</strong>：<code>ChatGoogleVertexAI</code>（支持图像+文本）</p>
</li>
</ul>
</blockquote>
<h3 id="Ollama">Ollama</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaEmbeddings, ChatOllama</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载检索知识库</span></span><br><span class="line">embedding = OllamaEmbeddings(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;nomic-embed-text&quot;</span>)</span><br><span class="line"></span><br><span class="line">loader = DirectoryLoader(<span class="string">&quot;./knowledge_base&quot;</span>, glob=<span class="string">&quot;*.txt&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">300</span>, chunk_overlap=<span class="number">50</span>)</span><br><span class="line">splits = text_splitter.split_documents(docs)</span><br><span class="line"></span><br><span class="line">vectorstore = Chroma.from_documents(</span><br><span class="line">    documents=splits,</span><br><span class="line">    embedding=embedding,</span><br><span class="line">    persist_directory=<span class="string">&quot;./data/vectorstore&quot;</span></span><br><span class="line">)</span><br><span class="line">retriever = vectorstore.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 调用模型</span></span><br><span class="line">query = <span class="string">&quot;推荐几种最新款式的衣服&quot;</span></span><br><span class="line">docs = retriever.invoke(query)</span><br><span class="line">context = <span class="string">&quot;\n\n&quot;</span>.join([doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> docs])</span><br><span class="line"><span class="keyword">if</span> <span class="keyword">not</span> context.strip():</span><br><span class="line">    <span class="keyword">return</span> <span class="string">&quot;知识库中未找到相关信息。&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = <span class="string">f&quot;你是一个客服，根据以下资料回答问题：\n\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">response = llm.invoke(prompt)</span><br></pre></td></tr></table></figure>
<h3 id="OpenAI">OpenAI</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI, OpenAIEmbeddings</span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o-mini&quot;</span>, temperature=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h3 id="千问">千问</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> ChatTongyi</span><br><span class="line"><span class="keyword">from</span> langchain_community.embeddings <span class="keyword">import</span> DashScopeEmbeddings</span><br><span class="line"></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;MODEL_NAME&quot;</span>, <span class="string">&quot;qwen-turbo&quot;</span>), <span class="comment"># 可选: qwen-turbo, qwen-plus, qwen-max, qwen-max-latest</span></span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;temperature&quot;</span>: <span class="number">0</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载知识库文档</span></span><br><span class="line">loader = DirectoryLoader(<span class="string">&quot;./knowledge_base&quot;</span>, glob=<span class="string">&quot;*.txt&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line">splits = RecursiveCharacterTextSplitter(chunk_size=<span class="number">300</span>, chunk_overlap=<span class="number">50</span>).split_documents(docs)</span><br><span class="line">vectorstore = Chroma.from_documents(splits, DashScopeEmbeddings(model=<span class="string">&quot;text-embedding-v1&quot;</span>), persist_directory=<span class="string">&quot;./data&quot;</span>)</span><br><span class="line"></span><br><span class="line">retriever = vectorstore.as_retriever(k=<span class="number">3</span>)</span><br><span class="line">query = <span class="string">&quot;最新的商品类型有哪些&quot;</span></span><br><span class="line">docs = retriever.invoke(query)</span><br><span class="line">context = <span class="string">&quot;\n\n&quot;</span>.join([d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line"></span><br><span class="line">prompt = <span class="string">f&quot;你是客服，请根据以下资料回答：\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">response = llm.invoke(prompt)</span><br></pre></td></tr></table></figure>
<h2 id="提示工程（Prompt">提示工程（Prompt)</h2>
<p>构建和管理提示词模板，支持动态填充、少量示例（few-shot）等。</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p><code>PromptTemplate</code>：传统字符串模板</p>
</li>
<li class="lvl-2">
<p><code>ChatPromptTemplate</code>：支持多轮对话消息（System/Human/AI）</p>
</li>
<li class="lvl-2">
<p><code>FewShotPromptTemplate</code>：带示例的提示</p>
</li>
<li class="lvl-2">
<p><code>MessagesPlaceholder</code>：用于 Agent 中的动态消息插槽</p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate, MessagesPlaceholder</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个订单查询助手。数据库包含 users(id, name) 和 orders(user_id, product, status) 表。\n&quot;</span></span><br><span class="line">               <span class="string">&quot;当用户提到姓名（如&#x27;张三&#x27;），请先从 users 表查 id，再关联 orders 表。\n&quot;</span></span><br><span class="line">               <span class="string">&quot;只用简洁明确的中文返回最终答案，不要输出 SQL 信息。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    MessagesPlaceholder(<span class="string">&quot;agent_scratchpad&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">db = SQLDatabase.from_uri(<span class="string">f&quot;sqlite:///<span class="subst">&#123;DB_PATH&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">agent = create_sql_agent(llm=llm, db=db, extra_prompt_messages=prompt.messages, agent_type=<span class="string">&quot;openai-tools&quot;</span>)</span><br><span class="line"></span><br><span class="line">result = agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: query&#125;)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"><span class="comment"># 创建自动摘要记忆</span></span><br><span class="line">summary_prompt = PromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;请将以下对话压缩成一段简洁的中文摘要，保留关键信息（如用户姓名、订单、问题类型）：\n\n&#123;summary&#125;\n\n当前对话：\nHuman: &#123;new_lines&#125;\nAI:&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">memory = ConversationSummaryMemory(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span>,  <span class="comment"># 以消息对象形式返回，兼容 Agent</span></span><br><span class="line">    human_prefix = <span class="string">&quot;Human&quot;</span>,</span><br><span class="line">    ai_prefix = <span class="string">&quot;AI&quot;</span>,</span><br><span class="line">    prompt = summary_prompt  <span class="comment"># 自定义摘要 prompt</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<h2 id="链式编排（Chain）">链式编排（Chain）</h2>
<p>将多个组件串联成流水线。</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p><strong>LLMChain</strong>：Prompt + LLM</p>
</li>
<li class="lvl-2">
<p><strong>SequentialChain</strong>：多步骤顺序执行</p>
</li>
<li class="lvl-2">
<p><strong>RetrievalQA</strong>：RAG 问答链</p>
</li>
<li class="lvl-2">
<p><strong>ConversationalRetrievalChain</strong>：带记忆的 RAG</p>
</li>
<li class="lvl-2">
<p><strong>自定义 Chain</strong>：通过 <code>RunnableSequence</code> 或 <code>RunnableLambda</code></p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> RetrievalQA</span><br><span class="line">qa_chain = RetrievalQA.from_chain_type(</span><br><span class="line">    llm=llm,</span><br><span class="line">    retriever=retriever,</span><br><span class="line">    chain_type=<span class="string">&quot;stuff&quot;</span></span><br><span class="line">)</span><br><span class="line">qa_chain.invoke(<span class="string">&quot;公司退货政策是什么？&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>直接手动构建链</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.chat_models <span class="keyword">import</span> ChatTongyi</span><br><span class="line"><span class="keyword">from</span> langchain_core.prompts <span class="keyword">import</span> ChatPromptTemplate</span><br><span class="line"><span class="keyword">from</span> langchain_core.output_parsers <span class="keyword">import</span> StrOutputParser</span><br><span class="line"></span><br><span class="line"><span class="comment">#################### llm</span></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;MODEL_NAME&quot;</span>, <span class="string">&quot;qwen-turbo&quot;</span>), </span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;temperature&quot;</span>: <span class="number">0</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">######################## 构建路由 Chain</span></span><br><span class="line">router_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个分类器，请严格输出以下三者之一：order_db, knowledge_base, general\n&quot;</span></span><br><span class="line">               <span class="string">&quot;规则：\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 涉及订单、用户、发货 → order_db\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 涉及退货、政策、说明书 → knowledge_base\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 其他 → general&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;问题：&#123;input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line">router_chain = router_prompt | llm | StrOutputParser()</span><br><span class="line">route = router_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_input&#125;).strip()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[路由结果: <span class="subst">&#123;route&#125;</span>]&quot;</span>)</span><br></pre></td></tr></table></figure>
<h2 id="智能决策（Agents）">智能决策（Agents）</h2>
<p>让 LLM <strong>自主调用工具</strong>（如搜索、数据库、API）。</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p><strong>Tools</strong>：封装函数为工具（<code>@tool</code> 装饰器）</p>
</li>
<li class="lvl-2">
<p>Agent Types：</p>
<ul class="lvl-3">
<li class="lvl-4"><code>openai-tools</code>：兼容 OpenAI Function Calling（推荐）</li>
<li class="lvl-4"><code>react</code>：ReAct 思维链</li>
<li class="lvl-4"><code>self-ask-with-search</code>：自问自答</li>
</ul>
</li>
<li class="lvl-2">
<p><strong>AgentExecutor</strong>：执行循环（Thought → Action → Observation）</p>
</li>
</ul>
</blockquote>
<ul class="lvl-0">
<li class="lvl-2">
<p>调用和执行DB</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.agent_toolkits <span class="keyword">import</span> create_sql_agent</span><br><span class="line"></span><br><span class="line">db = SQLDatabase.from_uri(<span class="string">f&quot;sqlite:///<span class="subst">&#123;DB_PATH&#125;</span>&quot;</span>)</span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">agent = create_sql_agent(llm=llm, db=db, agent_type=<span class="string">&quot;openai-tools&quot;</span>)</span><br><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    result = agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: query&#125;)</span><br><span class="line">    <span class="keyword">return</span> result[<span class="string">&quot;output&quot;</span>]</span><br><span class="line"><span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;数据库查询失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-2">
<p>调用和执行Tool</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> create_openai_tools_agent, AgentExecutor</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaEmbeddings, ChatOllama</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义 Tool</span></span><br><span class="line">tools = [</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;订单与用户查询&quot;</span>,</span><br><span class="line">        func=query_database,</span><br><span class="line">        description=<span class="string">&quot;用于查询用户的订单状态、购买记录、个人信息等结构化数据。&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;客服知识库查询&quot;</span>,</span><br><span class="line">        func=query_knowledge_base,</span><br><span class="line">        description=<span class="string">&quot;用于查询退换货政策、产品使用说明、常见问题等非结构化知识。&quot;</span></span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个智能客服助手。请根据用户问题选择合适的工具：\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 如果问题涉及订单、发货、用户信息等，请使用‘订单与用户查询’工具。\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 如果问题涉及退货、政策、产品说明等，请使用‘客服知识库查询’工具。\n&quot;</span></span><br><span class="line">               <span class="string">&quot;请用简洁、友好的中文回答。&quot;</span>),</span><br><span class="line">    MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">    MessagesPlaceholder(<span class="string">&quot;agent_scratchpad&quot;</span>)</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 管理 LLM、工具 和 提示词</span></span><br><span class="line">agent = create_openai_tools_agent(llm, tools, prompt)</span><br><span class="line">executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>, handle_parsing_errors=<span class="literal">True</span>)</span><br><span class="line">response = executor.invoke(&#123;</span><br><span class="line">            <span class="string">&quot;input&quot;</span>: user_input,</span><br><span class="line">            <span class="string">&quot;chat_history&quot;</span>: chat_history.messages</span><br><span class="line">        &#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="工具调用（Tool）">工具调用（Tool）</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_core.tools <span class="keyword">import</span> Tool</span><br><span class="line"><span class="keyword">from</span> langchain_ollama <span class="keyword">import</span> OllamaEmbeddings, ChatOllama</span><br><span class="line"></span><br><span class="line">tools = [</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;订单与用户查询&quot;</span>,</span><br><span class="line">        func=query_database,</span><br><span class="line">        description=<span class="string">&quot;用于查询用户的订单状态、购买记录、个人信息等结构化数据。&quot;</span></span><br><span class="line">    ),</span><br><span class="line">    Tool(</span><br><span class="line">        name=<span class="string">&quot;客服知识库查询&quot;</span>,</span><br><span class="line">        func=query_knowledge_base,</span><br><span class="line">        description=<span class="string">&quot;用于查询退换货政策、产品使用说明、常见问题等非结构化知识。&quot;</span></span><br><span class="line">    )</span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">agent = create_openai_tools_agent(llm, tools, <span class="string">&quot;prompt 模板&quot;</span>)</span><br><span class="line">executor = AgentExecutor(</span><br><span class="line">    agent=agent,</span><br><span class="line">    tools=tools,</span><br><span class="line">    verbose=<span class="literal">True</span>,</span><br><span class="line">    handle_parsing_errors=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">response = executor.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;你好&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;智能客服:&quot;</span>, response[<span class="string">&quot;output&quot;</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.tools <span class="keyword">import</span> tool</span><br><span class="line"></span><br><span class="line"><span class="comment"># @tool 装饰器用于将函数定义为一个工具</span></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">detect_scenes</span>(<span class="params">video_path: <span class="built_in">str</span></span>) -&gt; <span class="type">List</span>[<span class="type">Tuple</span>[<span class="built_in">float</span>, <span class="built_in">float</span>]]:</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">    	<span class="comment"># 此处为具体的工具实现</span></span><br><span class="line">        <span class="keyword">return</span> scenes</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="comment"># 发生错误时返回模拟数据</span></span><br><span class="line">        <span class="keyword">return</span> [(<span class="number">0.0</span>, <span class="number">5.0</span>), (<span class="number">5.0</span>, <span class="number">10.0</span>), (<span class="number">10.0</span>, <span class="number">15.0</span>)]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用@tool装饰器标记函数为工具</span></span><br><span class="line"><span class="meta">@tool</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_current_weather</span>(<span class="params">location: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取指定地点的当前天气&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment"># 这里应该是实际调用天气API的逻辑，简化为返回模拟数据</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">f&quot;<span class="subst">&#123;location&#125;</span>的当前天气是晴天，温度25°C&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 在Agent或其他链中可以直接调用工具函数</span></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    result = get_current_weather(<span class="string">&quot;北京&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(result)</span><br></pre></td></tr></table></figure>
<h2 id="状态记忆（Memory）">状态记忆（Memory）</h2>
<ul class="lvl-0">
<li class="lvl-2">
<p><strong>保存对话历史</strong>：让 LLM 知道上下文</p>
</li>
<li class="lvl-2">
<p><strong>维护状态</strong>：跟踪用户偏好、任务进度</p>
</li>
<li class="lvl-2">
<p><strong>支持多轮交互</strong>：如填表、分步任务</p>
</li>
</ul>
<table>
<thead>
<tr>
<th>类型</th>
<th>适用场景</th>
<th>特点</th>
</tr>
</thead>
<tbody>
<tr>
<td>ConversationBufferMemory</td>
<td>简单对话</td>
<td>保存全部历史（可能超 token）</td>
</tr>
<tr>
<td>ConversationBufferWindowMemory</td>
<td>长对话</td>
<td>仅保存最近 N 轮</td>
</tr>
<tr>
<td>ConversationSummaryMemory</td>
<td>超长对话</td>
<td>用 LLM 生成摘要</td>
</tr>
<tr>
<td>EntityMemory</td>
<td>实体跟踪</td>
<td>记住人物/物品属性</td>
</tr>
<tr>
<td>VectorStoreRetrieverMemory</td>
<td>知识库问答</td>
<td>从向量库检索相关记忆</td>
</tr>
</tbody>
</table>
<p>使用场景</p>
<table>
<thead>
<tr>
<th>场景</th>
<th>推荐 Memory 类型</th>
</tr>
</thead>
<tbody>
<tr>
<td>简单聊天机器人</td>
<td>ConversationBufferMemory</td>
</tr>
<tr>
<td>长对话（&gt;10轮）</td>
<td>ConversationBufferWindowMemory(k=5)</td>
</tr>
<tr>
<td>超长对话（&gt;50轮）</td>
<td>ConversationSummaryMemory</td>
</tr>
<tr>
<td>角色扮演/实体跟踪</td>
<td>ConversationEntityMemory</td>
</tr>
<tr>
<td>知识库问答</td>
<td>VectorStoreRetrieverMemory</td>
</tr>
<tr>
<td>生产环境持久化</td>
<td>RedisChatMessageHistory</td>
</tr>
</tbody>
</table>
<h3 id="基础记忆">基础记忆</h3>
<p>ConversationBufferMemory 的 <strong>简单对话链</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> ConversationChain</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"></span><br><span class="line">llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o&quot;</span>)</span><br><span class="line">memory = ConversationBufferMemory()</span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=llm,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 多轮对话</span></span><br><span class="line">response1 = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;你好！&quot;</span>)</span><br><span class="line">response2 = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我叫林然&quot;</span>)</span><br><span class="line">response3 = conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我刚才说了什么？&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(response3)  <span class="comment"># → &quot;你刚才说你叫林然&quot;</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 查看记忆内容</span></span><br><span class="line"><span class="built_in">print</span>(memory.load_memory_variables(&#123;&#125;))</span><br><span class="line"><span class="comment"># &#123;&#x27;history&#x27;: &#x27;Human: 你好！\nAI: 你好！有什么我可以帮你的吗？\nHuman: 我叫林然\nAI: 很高兴认识你，林然！&#x27;&#125;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 清空记忆</span></span><br><span class="line">memory.clear()</span><br></pre></td></tr></table></figure>
<h3 id="窗口记忆（长对话）">窗口记忆（长对话）</h3>
<p>避免 token 超限，只保留最近 3 轮：Window Memory</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferWindowMemory</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferWindowMemory(k=<span class="number">3</span>)  <span class="comment"># 保留最近3轮</span></span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对话超过3轮后，最早的内容会被丢弃</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">5</span>):</span><br><span class="line">    conversation.predict(<span class="built_in">input</span>=<span class="string">f&quot;消息<span class="subst">&#123;i+<span class="number">1</span>&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line"><span class="comment"># 查看当前记忆（应只有最后3轮）</span></span><br><span class="line">history = memory.load_memory_variables(&#123;&#125;)[<span class="string">&quot;history&quot;</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;\n当前记忆轮数: <span class="subst">&#123;history.count(<span class="string">&#x27;Human:&#x27;</span>)&#125;</span>&quot;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;记忆内容:\n<span class="subst">&#123;history&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
<h3 id="摘要记忆（超长对话）">摘要记忆（超长对话）</h3>
<p>用 LLM 自动摘要历史：Summary Memory</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationSummaryMemory</span><br><span class="line"></span><br><span class="line">memory = ConversationSummaryMemory(</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 随着对话增长，memory 会自动摘要</span></span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我们来玩角色扮演&quot;</span>)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;你扮演医生&quot;</span>)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我头痛三天了&quot;</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>特别注意：</p>
<ul class="lvl-1">
<li class="lvl-2">
<p>如果 <code>return_messages=True</code> 则存储的对象为 <strong>List[BaseMessage]</strong>，获取时需要转换为 文本内容，一般需要注入 记忆注入点<code>MessagesPlaceholder(&quot;chat_history&quot;)</code>，还有压缩时summary_prompt的影响，是独立存储时才需要获取最近几轮的切片操作。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将消息转为文本</span></span><br><span class="line">history = <span class="string">&quot;\n&quot;</span>.join(</span><br><span class="line">    <span class="string">f&quot;<span class="subst">&#123;<span class="string">&#x27;用户&#x27;</span> <span class="keyword">if</span> m.<span class="built_in">type</span> == <span class="string">&#x27;human&#x27;</span> <span class="keyword">else</span> <span class="string">&#x27;客服&#x27;</span>&#125;</span>: <span class="subst">&#123;m.content&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">for</span> m <span class="keyword">in</span> <span class="variable language_">self</span>.get_summary_recent(<span class="number">6</span>)  <span class="comment"># 最近6轮</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-2">
<p>如果 <code>return_messages=False</code> ，不需要注入 <code>MessagesPlaceholder(&quot;chat_history&quot;)</code>。</p>
</li>
</ul>
</blockquote>
<h3 id="实体记忆">实体记忆</h3>
<p>记住对话中提到的<strong>实体属性</strong>（如人物、物品）：EntityMemory</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationEntityMemory</span><br><span class="line"><span class="keyword">from</span> langchain.memory.prompt <span class="keyword">import</span> ENTITY_MEMORY_CONVERSATION_TEMPLATE</span><br><span class="line"></span><br><span class="line">entity_memory = ConversationEntityMemory(llm=ChatOpenAI())</span><br><span class="line"></span><br><span class="line">conversation = ConversationChain(</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,</span><br><span class="line">    memory=entity_memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我叫林然，32岁&quot;</span>)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我喜欢喝红茶&quot;</span>)</span><br><span class="line">conversation.predict(<span class="built_in">input</span>=<span class="string">&quot;我住在北京&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看实体记忆</span></span><br><span class="line"><span class="built_in">print</span>(entity_memory.entity_cache)</span><br><span class="line"><span class="comment"># &#123;&#x27;林然&#x27;: &#x27;32岁，喜欢喝红茶，住在北京&#x27;&#125;</span></span><br></pre></td></tr></table></figure>
<h3 id="向量记忆（知识库）">向量记忆（知识库）</h3>
<p>从<strong>向量数据库</strong>中检索相关记忆（适合知识库），向量记忆：VectorStoreRetrieverMemory</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> VectorStoreRetrieverMemory</span><br><span class="line"><span class="keyword">from</span> langchain_community.vectorstores <span class="keyword">import</span> FAISS</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> OpenAIEmbeddings</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. 创建向量库</span></span><br><span class="line">embedding = OpenAIEmbeddings()</span><br><span class="line">vectorstore = FAISS.from_texts(</span><br><span class="line">    [<span class="string">&quot;林然喜欢红茶&quot;</span>, <span class="string">&quot;陈默是林然的前男友&quot;</span>, <span class="string">&quot;北京今天下雨&quot;</span>],</span><br><span class="line">    embedding</span><br><span class="line">)</span><br><span class="line">retriever = vectorstore.as_retriever()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 创建记忆</span></span><br><span class="line">memory = VectorStoreRetrieverMemory(retriever=retriever)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 在链中使用</span></span><br><span class="line"><span class="keyword">from</span> langchain.chains <span class="keyword">import</span> LLMChain</span><br><span class="line"><span class="keyword">from</span> langchain.prompts <span class="keyword">import</span> PromptTemplate</span><br><span class="line"></span><br><span class="line">template = <span class="string">&quot;&quot;&quot;你是一个助手，会参考相关记忆回答问题。</span></span><br><span class="line"><span class="string">记忆: &#123;retrieved_memories&#125;</span></span><br><span class="line"><span class="string">问题: &#123;input&#125;</span></span><br><span class="line"><span class="string">回答:&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line">prompt = PromptTemplate.from_template(template)</span><br><span class="line">chain = LLMChain(</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    prompt=prompt,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">chain.predict(<span class="built_in">input</span>=<span class="string">&quot;林然喜欢什么？&quot;</span>)  <span class="comment"># → 从向量库检索&quot;林然喜欢红茶&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="Agent-工具">Agent 工具</h3>
<p>让 Agent 记住工具调用历史：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.agents <span class="keyword">import</span> AgentType, initialize_agent</span><br><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">agent = initialize_agent(</span><br><span class="line">    tools=[],</span><br><span class="line">    llm=ChatOpenAI(),</span><br><span class="line">    agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,</span><br><span class="line">    memory=memory,</span><br><span class="line">    verbose=<span class="literal">True</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">agent.run(<span class="string">&quot;记住我的名字是林然&quot;</span>)</span><br><span class="line">agent.run(<span class="string">&quot;我叫什么？&quot;</span>)  <span class="comment"># → &quot;你叫林然&quot;</span></span><br></pre></td></tr></table></figure>
<h3 id="持久化记忆">持久化记忆</h3>
<p><strong>保存到文件</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pickle</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;memory.pkl&#x27;</span>, <span class="string">&#x27;wb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    pickle.dump(memory, f)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载</span></span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&#x27;memory.pkl&#x27;</span>, <span class="string">&#x27;rb&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    memory = pickle.load(f)</span><br></pre></td></tr></table></figure>
<p><strong>保存到 Redis（生产推荐）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain.memory <span class="keyword">import</span> ConversationBufferMemory</span><br><span class="line"><span class="keyword">from</span> langchain_community.storage <span class="keyword">import</span> RedisChatMessageHistory</span><br><span class="line"></span><br><span class="line">message_history = RedisChatMessageHistory(</span><br><span class="line">    session_id=<span class="string">&quot;user_123&quot;</span>,</span><br><span class="line">    url=<span class="string">&quot;redis://localhost:6379/0&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    chat_memory=message_history,</span><br><span class="line">    return_messages=<span class="literal">True</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
<p><strong>保存到 PostgreSQL</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langchain_community.chat_message_histories <span class="keyword">import</span> PostgresChatMessageHistory</span><br><span class="line"></span><br><span class="line">history = PostgresChatMessageHistory(</span><br><span class="line">    session_id=<span class="string">&quot;user_123&quot;</span>,</span><br><span class="line">    connection_string=<span class="string">&quot;postgresql://user:pass@localhost/db&quot;</span></span><br><span class="line">)</span><br><span class="line">memory = ConversationBufferMemory(chat_memory=history)</span><br></pre></td></tr></table></figure>
<h3 id="高级技巧">高级技巧</h3>
<ol>
<li class="lvl-3">
<p><strong>自定义 Memory Key</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">memory = ConversationBufferMemory(</span><br><span class="line">    memory_key=<span class="string">&quot;conversation_history&quot;</span>,  <span class="comment"># 自定义 key</span></span><br><span class="line">    input_key=<span class="string">&quot;user_input&quot;</span>             <span class="comment"># 指定输入 key</span></span><br><span class="line">)</span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-3">
<p><strong>LangGraph 中使用 Memory</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, END</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AgentState</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line">    memory: <span class="built_in">dict</span>  <span class="comment"># 自定义 memory 字段</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_model</span>(<span class="params">state: AgentState</span>):</span><br><span class="line">    <span class="comment"># 从 state[&quot;memory&quot;] 读取历史</span></span><br><span class="line">    response = llm.invoke(state[<span class="string">&quot;messages&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;</span><br><span class="line"></span><br><span class="line">workflow = StateGraph(AgentState)</span><br><span class="line">workflow.add_node(<span class="string">&quot;agent&quot;</span>, call_model)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># LangGraph 中的自定义记忆</span></span><br><span class="line"><span class="keyword">from</span> typing <span class="keyword">import</span> Annotated, <span class="type">Sequence</span></span><br><span class="line"><span class="keyword">from</span> langchain_core.messages <span class="keyword">import</span> BaseMessage, HumanMessage, AIMessage</span><br><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"><span class="keyword">from</span> langgraph.graph.message <span class="keyword">import</span> add_messages</span><br><span class="line"><span class="keyword">from</span> langchain_openai <span class="keyword">import</span> ChatOpenAI</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">from</span> dotenv <span class="keyword">import</span> load_dotenv</span><br><span class="line"></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义状态</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">GraphState</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="type">Sequence</span>[BaseMessage], add_messages]</span><br><span class="line">    user_name: <span class="built_in">str</span>  <span class="comment"># 自定义记忆字段</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 节点函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">call_model</span>(<span class="params">state: GraphState</span>):</span><br><span class="line">    llm = ChatOpenAI(model=<span class="string">&quot;gpt-4o&quot;</span>)</span><br><span class="line">    response = llm.invoke(state[<span class="string">&quot;messages&quot;</span>])</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [response]&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_name</span>(<span class="params">state: GraphState</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;从对话中提取用户名&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> state.get(<span class="string">&quot;user_name&quot;</span>):</span><br><span class="line">        <span class="keyword">for</span> msg <span class="keyword">in</span> <span class="built_in">reversed</span>(state[<span class="string">&quot;messages&quot;</span>]):</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, HumanMessage):</span><br><span class="line">                <span class="keyword">if</span> <span class="string">&quot;我叫&quot;</span> <span class="keyword">in</span> msg.content:</span><br><span class="line">                    name = msg.content.split(<span class="string">&quot;我叫&quot;</span>)[-<span class="number">1</span>].strip(<span class="string">&quot;。！&quot;</span>)</span><br><span class="line">                    <span class="keyword">return</span> &#123;<span class="string">&quot;user_name&quot;</span>: name&#125;</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;user_name&quot;</span>: state.get(<span class="string">&quot;user_name&quot;</span>, <span class="string">&quot;&quot;</span>)&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建图</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_graph</span>():</span><br><span class="line">    workflow = StateGraph(GraphState)</span><br><span class="line">    workflow.add_node(<span class="string">&quot;extract_name&quot;</span>, extract_name)</span><br><span class="line">    workflow.add_node(<span class="string">&quot;call_model&quot;</span>, call_model)</span><br><span class="line">    </span><br><span class="line">    workflow.set_entry_point(<span class="string">&quot;extract_name&quot;</span>)</span><br><span class="line">    workflow.add_edge(<span class="string">&quot;extract_name&quot;</span>, <span class="string">&quot;call_model&quot;</span>)</span><br><span class="line">    workflow.add_edge(<span class="string">&quot;call_model&quot;</span>, END)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> workflow.<span class="built_in">compile</span>()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    app = create_graph()</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;=== LangGraph 记忆测试 ===&quot;</span>)</span><br><span class="line">    inputs = &#123;<span class="string">&quot;messages&quot;</span>: [HumanMessage(content=<span class="string">&quot;你好！我叫林然&quot;</span>)]&#125;</span><br><span class="line">    result = app.invoke(inputs)</span><br><span class="line">    </span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\nAI 回答: <span class="subst">&#123;result[<span class="string">&#x27;messages&#x27;</span>][-<span class="number">1</span>].content&#125;</span>&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;提取的用户名: <span class="subst">&#123;result[<span class="string">&#x27;user_name&#x27;</span>]&#125;</span>&quot;</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 第二轮对话</span></span><br><span class="line">    inputs2 = &#123;</span><br><span class="line">        <span class="string">&quot;messages&quot;</span>: result[<span class="string">&quot;messages&quot;</span>] + [HumanMessage(content=<span class="string">&quot;你还记得我吗？&quot;</span>)],</span><br><span class="line">        <span class="string">&quot;user_name&quot;</span>: result[<span class="string">&quot;user_name&quot;</span>]</span><br><span class="line">    &#125;</span><br><span class="line">    result2 = app.invoke(inputs2)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;\n第二轮回答: <span class="subst">&#123;result2[<span class="string">&#x27;messages&#x27;</span>][-<span class="number">1</span>].content&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-3">
<p><strong>记忆过滤（敏感信息）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">SafeMemory</span>(<span class="title class_ inherited__">ConversationBufferMemory</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">save_context</span>(<span class="params">self, inputs, outputs</span>):</span><br><span class="line">        <span class="comment"># 过滤身份证/手机号</span></span><br><span class="line">        inputs = &#123;k: v.replace(<span class="string">&quot;138****1234&quot;</span>, <span class="string">&quot;[PHONE]&quot;</span>) <span class="keyword">for</span> k, v <span class="keyword">in</span> inputs.items()&#125;</span><br><span class="line">        <span class="built_in">super</span>().save_context(inputs, outputs)</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h3 id="上下文理解">上下文理解</h3>
<p>从之前的历史记录中获取信息，并注入到当前对话中。</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>从 langgraph 的 AgentState 对象中获取 summary，然后通过LLM提取关键上下文数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 获取原始问题</span></span><br><span class="line">original_query = <span class="string">&quot;介绍一下这个商品&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 结合摘要和最近消息，重写查询</span></span><br><span class="line">summary = state.get(<span class="string">&quot;summary&quot;</span>, <span class="string">&quot;&quot;</span>)</span><br><span class="line">recent_msgs = state[<span class="string">&quot;messages&quot;</span>][-<span class="number">3</span>:]  <span class="comment"># 最近2-3条</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 构建上下文字符串</span></span><br><span class="line">context_parts = []</span><br><span class="line"><span class="keyword">if</span> summary:</span><br><span class="line">    context_parts.append(<span class="string">f&quot;背景摘要：<span class="subst">&#123;summary&#125;</span>&quot;</span>)</span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> recent_msgs[:-<span class="number">1</span>]:  <span class="comment"># 不包含当前问题</span></span><br><span class="line">    role = <span class="string">&quot;用户&quot;</span> <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, HumanMessage) <span class="keyword">else</span> <span class="string">&quot;客服&quot;</span></span><br><span class="line">    context_parts.append(<span class="string">f&quot;<span class="subst">&#123;role&#125;</span>: <span class="subst">&#123;msg.content&#125;</span>&quot;</span>)</span><br><span class="line"></span><br><span class="line">context_str = <span class="string">&quot;\n&quot;</span>.join(context_parts)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 让 LLM 重写查询（消除指代）</span></span><br><span class="line"><span class="keyword">if</span> context_str.strip():</span><br><span class="line">    rewrite_prompt = [</span><br><span class="line">        SystemMessage(content=<span class="string">&quot;你是一个查询重写助手。请结合对话上下文，将用户的当前问题改写为一个独立、明确、无指代的完整问题。&quot;</span>),</span><br><span class="line">        HumanMessage(content=<span class="string">f&quot;上下文：\n<span class="subst">&#123;context_str&#125;</span>\n\n当前问题：<span class="subst">&#123;original_query&#125;</span>\n\n改写后的问题：&quot;</span>)</span><br><span class="line">    ]</span><br><span class="line">    rewritten = llm.invoke(rewrite_prompt)</span><br><span class="line">    enhanced_query = rewritten.content.strip()</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    enhanced_query = original_query</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[RAG 调试] 原始查询: &#x27;<span class="subst">&#123;original_query&#125;</span>&#x27; → 增强查询: &#x27;<span class="subst">&#123;enhanced_query&#125;</span>&#x27;&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 用增强查询执行 RAG</span></span><br><span class="line">retriever = init_rag().as_retriever(k=<span class="number">3</span>)</span><br><span class="line">docs = retriever.invoke(enhanced_query)</span><br><span class="line">context = <span class="string">&quot;\n\n&quot;</span>.join([d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> docs]) <span class="keyword">or</span> <span class="string">&quot;知识库中未找到相关信息。&quot;</span></span><br><span class="line"></span><br><span class="line">answer_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是客服，请根据以下资料简洁回答问题，不要反问。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">f&quot;资料：<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;enhanced_query&#125;</span>&quot;</span>)</span><br><span class="line">])</span><br><span class="line">rag_chain = answer_prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line">result = rag_chain.invoke(&#123;<span class="string">&quot;context&quot;</span>: context, <span class="string">&quot;query&quot;</span>: enhanced_query&#125;)</span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-2">
<p>从 langgraph 的 AgentState 对象中获取 summary，然后自己解析提取关键上下文数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 从对话历史中提取用户身份</span></span><br><span class="line">user_name = <span class="literal">None</span></span><br><span class="line"><span class="keyword">for</span> msg <span class="keyword">in</span> state[<span class="string">&quot;messages&quot;</span>]:</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">isinstance</span>(msg, HumanMessage):</span><br><span class="line">        content = msg.content</span><br><span class="line">        <span class="keyword">if</span> <span class="string">&quot;我是&quot;</span> <span class="keyword">in</span> content <span class="keyword">or</span> <span class="string">&quot;我叫&quot;</span> <span class="keyword">in</span> content <span class="keyword">or</span> <span class="string">&quot;我的名字是&quot;</span> <span class="keyword">in</span> content:</span><br><span class="line">            <span class="comment"># 简单提取姓名（可扩展为 NER）</span></span><br><span class="line">            <span class="keyword">for</span> keyword <span class="keyword">in</span> [<span class="string">&quot;我是&quot;</span>, <span class="string">&quot;我叫&quot;</span>, <span class="string">&quot;我的名字是&quot;</span>]:</span><br><span class="line">                <span class="keyword">if</span> keyword <span class="keyword">in</span> content:</span><br><span class="line">                    name = content.split(keyword)[-<span class="number">1</span>].strip(<span class="string">&quot;。！？,. &quot;</span>)</span><br><span class="line">                    <span class="keyword">if</span> name:</span><br><span class="line">                        user_name = name</span><br><span class="line">                        <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> user_name:</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 改写用户查询，显式包含用户名</span></span><br><span class="line">original_query = state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">enhanced_query = <span class="string">f&quot;（当前用户姓名：<span class="subst">&#123;user_name&#125;</span>）<span class="subst">&#123;original_query&#125;</span>&quot;</span> <span class="keyword">if</span> user_name <span class="keyword">else</span> original_query</span><br><span class="line"><span class="built_in">print</span>(<span class="string">f&quot;[DB 调试] 增强后查询: <span class="subst">&#123;enhanced_query&#125;</span>&quot;</span>)</span><br></pre></td></tr></table></figure>
</li>
<li class="lvl-2">
<p>从 <code>ConversationSummaryMemory </code>对象中获取 chat_history，然后通过LLM解析提取关键上下文数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建自动摘要记忆</span></span><br><span class="line">summary_prompt = PromptTemplate.from_template(</span><br><span class="line">    <span class="string">&quot;请将以下对话压缩成一段简洁的中文摘要，保留关键信息（如用户姓名、订单、问题类型）：\n\n&#123;summary&#125;\n\n当前对话：\nHuman: &#123;new_lines&#125;\nAI:&quot;</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">summary_memory = ConversationSummaryMemory(</span><br><span class="line">    llm=<span class="variable language_">self</span>.llm,</span><br><span class="line">    memory_key=<span class="string">&quot;chat_history&quot;</span>,</span><br><span class="line">    return_messages=<span class="literal">False</span>,  <span class="comment"># 如果是 True 以消息对象形式返回，兼容 Agent。 如果 False 则返回纯文本摘要</span></span><br><span class="line">    human_prefix=<span class="string">&quot;Human&quot;</span>,</span><br><span class="line">    ai_prefix=<span class="string">&quot;AI&quot;</span>,</span><br><span class="line">    prompt=summary_prompt  <span class="comment"># 自定义摘要 prompt</span></span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_summary_recent</span>(<span class="params">self, recent_n=<span class="number">6</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;获取最近 N 条对话消息&quot;&quot;&quot;</span></span><br><span class="line">    messages = summary_memory.load_memory_variables(&#123;&#125;)[<span class="string">&quot;chat_history&quot;</span>]</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(messages) &gt; recent_n:</span><br><span class="line">        <span class="keyword">return</span> messages[-recent_n:]   <span class="comment"># 最近 N 条</span></span><br><span class="line">    <span class="keyword">return</span> messages</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">extract_last_user_name</span>(<span class="params">self</span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    recent_messages = <span class="variable language_">self</span>.get_summary_recent() </span><br><span class="line">    prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个信息提取助手。请仔细阅读以下对话历史，&quot;</span></span><br><span class="line">                   <span class="string">&quot;并提取用户在**最近一次发言**中提到的关键信息。&quot;</span></span><br><span class="line">                   <span class="string">&quot;只返回所需内容，不要解释。&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;对话历史：&#123;history&#125;\n\n&quot;</span></span><br><span class="line">                  <span class="string">&quot;问题：用户最近提到的姓名是什么？如果没有，返回“未知”。\n&quot;</span></span><br><span class="line">                  <span class="string">&quot;姓名：&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    chain = prompt | <span class="variable language_">self</span>.llm | StrOutputParser()</span><br><span class="line">    <span class="keyword">return</span> chain.invoke(&#123;<span class="string">&quot;history&quot;</span>: recent_messages&#125;)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h2 id="状态图（LangGraph）">状态图（LangGraph）</h2>
<p>用于构建 <strong>可控、循环、分支、多智能体协作</strong> 的复杂工作流。</p>
<blockquote>
<ul class="lvl-1">
<li class="lvl-2">
<p>基于状态（State）驱动</p>
</li>
<li class="lvl-2">
<p>支持条件分支、循环、并行</p>
</li>
<li class="lvl-2">
<p>天然支持多智能体路由</p>
</li>
<li class="lvl-2">
<p>可中断、可恢复、可调试</p>
</li>
</ul>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> langgraph.graph <span class="keyword">import</span> StateGraph, START, END</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">State</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line"></span><br><span class="line">builder = StateGraph(State)</span><br><span class="line">builder.add_node(<span class="string">&quot;chatbot&quot;</span>, chatbot_node)</span><br><span class="line">builder.add_edge(START, <span class="string">&quot;chatbot&quot;</span>)</span><br><span class="line">builder.add_edge(<span class="string">&quot;chatbot&quot;</span>, END)</span><br><span class="line">graph = builder.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<h2 id="基础-Demo"><a href="https://github.com/HengLine/langchain-demo/blob/main/base_demo.py">基础 Demo</a></h2>
<p>加载、解析、检索文档，构建问答链和模板，输出响应</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 1. 加载文档</span></span><br><span class="line">loader = PyPDFLoader(<span class="string">&quot;C:\\Users\\haeng\\Desktop\\大数据技术详解.pdf&quot;</span>)</span><br><span class="line">docs = loader.load()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. 分块</span></span><br><span class="line">text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">1000</span>, chunk_overlap=<span class="number">200</span>)</span><br><span class="line">splits = text_splitter.split_documents(docs)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 3. 嵌入并存入向量库</span></span><br><span class="line">vectorstore = Chroma.from_documents(documents=splits</span><br><span class="line">           , embedding=OllamaEmbeddings(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;nomic-embed-text&quot;</span>)</span><br><span class="line">           , persist_directory=<span class="string">&quot;./data/chroma_db&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 4. 创建检索器</span></span><br><span class="line">retriever = vectorstore.as_retriever()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 5. 构建问答链</span></span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:0.6b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">system_prompt = (</span><br><span class="line">    <span class="string">&quot;你是一个乐于助人的智能助手，请根据以下上下文回答用户问题。&quot;</span></span><br><span class="line">    <span class="string">&quot;\n\n&quot;</span></span><br><span class="line">    <span class="string">&quot;&#123;context&#125;&quot;</span></span><br><span class="line">)</span><br><span class="line"><span class="comment"># 构建提示模板</span></span><br><span class="line">prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, system_prompt),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 创建 chain</span></span><br><span class="line">question_answer_chain = create_stuff_documents_chain(llm, prompt)</span><br><span class="line">rag_chain = create_retrieval_chain(retriever, question_answer_chain)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 6. 提问</span></span><br><span class="line">response = rag_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: <span class="string">&quot;总结一下这份文档主要讲了什么内容？&quot;</span>&#125;)</span><br><span class="line"><span class="built_in">print</span>(response[<span class="string">&quot;answer&quot;</span>])</span><br></pre></td></tr></table></figure>
<h2 id="智能客服机器人"><a href="https://github.com/HengLine/langchain-demo/blob/main/hybrid/">智能客服机器人</a></h2>
<p>LangChain Agent（路由决策）：</p>
<ul class="lvl-0">
<li class="lvl-2">
<p>若问题涉及订单/用户/状态 → 调用 SQL DB 工具</p>
</li>
<li class="lvl-2">
<p>若问题涉及政策/说明/FAQ → 调用 RAG 知识库工具（knowledge_base 文件夹下）</p>
<ul class="lvl-2">
<li class="lvl-4">return_policy.txt（退换货政策）</li>
<li class="lvl-4">product_guide.txt（产品使用指南）</li>
</ul>
</li>
<li class="lvl-2">
<p>其他问题直接调用LLM</p>
</li>
</ul>
<h3 id="单智能体"><a href="https://github.com/HengLine/langchain-demo/blob/main/hybrid/hybrid_bot_agent.py">单智能体</a></h3>
<p>支持多轮对话，记忆上下文</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 1. 初始化数据库</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line">DB_PATH = <span class="string">&quot;../data/customer_service.db&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_database</span>():</span><br><span class="line">    <span class="keyword">if</span> os.path.exists(DB_PATH):</span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    conn = sqlite3.connect(DB_PATH)</span><br><span class="line">    cursor = conn.cursor()</span><br><span class="line">    cursor.execute(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        CREATE TABLE users (id INTEGER PRIMARY KEY, name TEXT, email TEXT)</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span>)</span><br><span class="line">    cursor.execute(<span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">        CREATE TABLE orders (</span></span><br><span class="line"><span class="string">            id INTEGER PRIMARY KEY,</span></span><br><span class="line"><span class="string">            user_id INTEGER,</span></span><br><span class="line"><span class="string">            product TEXT,</span></span><br><span class="line"><span class="string">            status TEXT,</span></span><br><span class="line"><span class="string">            order_date TEXT,</span></span><br><span class="line"><span class="string">            FOREIGN KEY(user_id) REFERENCES users(id)</span></span><br><span class="line"><span class="string">        )</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span>)</span><br><span class="line">    cursor.executemany(<span class="string">&quot;INSERT INTO users VALUES (?, ?, ?)&quot;</span>, [</span><br><span class="line">        (<span class="number">1</span>, <span class="string">&quot;张三&quot;</span>, <span class="string">&quot;zhangsan@example.com&quot;</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="string">&quot;李四&quot;</span>, <span class="string">&quot;lisi@example.com&quot;</span>),</span><br><span class="line">    ])</span><br><span class="line">    cursor.executemany(<span class="string">&quot;INSERT INTO orders VALUES (?, ?, ?, ?, ?)&quot;</span>, [</span><br><span class="line">        (<span class="number">1</span>, <span class="number">1</span>, <span class="string">&quot;无线蓝牙耳机&quot;</span>, <span class="string">&quot;delivered&quot;</span>, <span class="string">&quot;2024-10-01&quot;</span>),</span><br><span class="line">        (<span class="number">2</span>, <span class="number">2</span>, <span class="string">&quot;机械键盘&quot;</span>, <span class="string">&quot;shipped&quot;</span>, <span class="string">&quot;2025-11-01&quot;</span>),</span><br><span class="line">        (<span class="number">3</span>, <span class="number">1</span>, <span class="string">&quot;智能手机&quot;</span>, <span class="string">&quot;shipped&quot;</span>, <span class="string">&quot;2025-09-01&quot;</span>),</span><br><span class="line">        (<span class="number">4</span>, <span class="number">2</span>, <span class="string">&quot;显示器支架&quot;</span>, <span class="string">&quot;pending&quot;</span>, <span class="string">&quot;2025-11-11&quot;</span>),</span><br><span class="line">    ])</span><br><span class="line">    conn.commit()</span><br><span class="line">    conn.close()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 2. 初始化 RAG 知识库</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line">KNOWLEDGE_DIR = <span class="string">&quot;./knowledge_base&quot;</span></span><br><span class="line">VECTOR_STORE_PATH = <span class="string">&quot;../data/vectorstore&quot;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_rag</span>():</span><br><span class="line">    embedding = OllamaEmbeddings(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;nomic-embed-text&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> os.path.exists(VECTOR_STORE_PATH):</span><br><span class="line">        vectorstore = Chroma(</span><br><span class="line">            persist_directory=VECTOR_STORE_PATH,</span><br><span class="line">            embedding_function=embedding</span><br><span class="line">        )</span><br><span class="line">        <span class="keyword">return</span> vectorstore.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line"></span><br><span class="line">    loader = DirectoryLoader(KNOWLEDGE_DIR, glob=<span class="string">&quot;*.txt&quot;</span>)</span><br><span class="line">    docs = loader.load()</span><br><span class="line">    text_splitter = RecursiveCharacterTextSplitter(chunk_size=<span class="number">300</span>, chunk_overlap=<span class="number">50</span>)</span><br><span class="line">    splits = text_splitter.split_documents(docs)</span><br><span class="line"></span><br><span class="line">    vectorstore = Chroma.from_documents(</span><br><span class="line">        documents=splits,</span><br><span class="line">        embedding=embedding,</span><br><span class="line">        persist_directory=VECTOR_STORE_PATH</span><br><span class="line">    )</span><br><span class="line">    <span class="keyword">return</span> vectorstore.as_retriever(search_kwargs=&#123;<span class="string">&quot;k&quot;</span>: <span class="number">3</span>&#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 3. 定义工具函数</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">query_database</span>(<span class="params">query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;查询订单、用户等结构化数据&quot;&quot;&quot;</span></span><br><span class="line">    db = SQLDatabase.from_uri(<span class="string">f&quot;sqlite:///<span class="subst">&#123;DB_PATH&#125;</span>&quot;</span>)</span><br><span class="line">    llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">from</span> langchain_community.agent_toolkits <span class="keyword">import</span> create_sql_agent</span><br><span class="line">    agent = create_sql_agent(llm=llm, db=db, agent_type=<span class="string">&quot;openai-tools&quot;</span>)</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: query&#125;)</span><br><span class="line">        <span class="keyword">return</span> result[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;数据库查询失败: <span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">query_knowledge_base</span>(<span class="params">query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="string">&quot;&quot;&quot;查询退换货政策、产品说明等非结构化知识&quot;&quot;&quot;</span></span><br><span class="line">    retriever = init_rag()</span><br><span class="line">    docs = retriever.invoke(query)</span><br><span class="line">    context = <span class="string">&quot;\n\n&quot;</span>.join([doc.page_content <span class="keyword">for</span> doc <span class="keyword">in</span> docs])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> context.strip():</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;知识库中未找到相关信息。&quot;</span></span><br><span class="line">    <span class="comment"># 使用 LLM 生成自然语言回答</span></span><br><span class="line">    llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line">    prompt = <span class="string">f&quot;你是一个客服，根据以下资料回答问题：\n\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">    response = llm.invoke(prompt)</span><br><span class="line">    <span class="keyword">return</span> response.content</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 4. 创建混合 Agent，指定 Tool</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">create_hybrid_agent</span>():</span><br><span class="line">    tools = [</span><br><span class="line">        Tool(</span><br><span class="line">            name=<span class="string">&quot;订单与用户查询&quot;</span>,</span><br><span class="line">            func=query_database,</span><br><span class="line">            description=<span class="string">&quot;用于查询用户的订单状态、购买记录、个人信息等结构化数据。&quot;</span></span><br><span class="line">        ),</span><br><span class="line">        Tool(</span><br><span class="line">            name=<span class="string">&quot;客服知识库查询&quot;</span>,</span><br><span class="line">            func=query_knowledge_base,</span><br><span class="line">            description=<span class="string">&quot;用于查询退换货政策、产品使用说明、常见问题等非结构化知识。&quot;</span></span><br><span class="line">        )</span><br><span class="line">    ]</span><br><span class="line"></span><br><span class="line">    llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:4b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Agent 系统提示</span></span><br><span class="line">    prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个智能客服助手。请根据用户问题选择合适的工具：\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;- 如果问题涉及订单、发货、用户信息等，请使用‘订单与用户查询’工具。\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;- 如果问题涉及退货、政策、产品说明等，请使用‘客服知识库查询’工具。\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;请用简洁、友好的中文回答。&quot;</span>),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;chat_history&quot;</span>),  <span class="comment"># ←←← 记忆注入点</span></span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>),</span><br><span class="line">        MessagesPlaceholder(<span class="string">&quot;agent_scratchpad&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">    agent = create_openai_tools_agent(llm, tools, prompt)</span><br><span class="line">    executor = AgentExecutor(agent=agent, tools=tools, verbose=<span class="literal">True</span>, handle_parsing_errors=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> executor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 5. 主程序</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    init_database()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;智能客服机器人（数据库 + RAG 知识库 + 多轮记忆）已启动！&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;你可以提问：&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;  - 张三最新的订单状态？&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;  - 退货政策是什么？&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;  - 蓝牙耳机怎么用？&quot;</span>)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;输入 &#x27;quit&#x27; 退出。\n&quot;</span>)</span><br><span class="line"></span><br><span class="line">    agent = create_hybrid_agent()</span><br><span class="line">    chat_history = ChatMessageHistory()  <span class="comment"># 存储对话历史</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        user_input = <span class="built_in">input</span>(<span class="string">&quot;用户: &quot;</span>).strip()</span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> user_input:</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> user_input <span class="keyword">and</span> user_input.lower() <span class="keyword">in</span> &#123;<span class="string">&quot;quit&quot;</span>, <span class="string">&quot;exit&quot;</span>&#125;:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;再见！&quot;</span>)</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            <span class="comment"># response = agent.invoke(&#123;&quot;input&quot;: user_input&#125;)</span></span><br><span class="line">            response = agent.invoke(&#123;</span><br><span class="line">                <span class="string">&quot;input&quot;</span>: user_input,</span><br><span class="line">                <span class="string">&quot;chat_history&quot;</span>: chat_history.messages</span><br><span class="line">            &#125;)</span><br><span class="line">            <span class="comment"># 保存本轮对话到历史</span></span><br><span class="line">            chat_history.add_user_message(user_input)</span><br><span class="line">            chat_history.add_ai_message(response[<span class="string">&quot;output&quot;</span>])</span><br><span class="line"></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;智能客服:&quot;</span>, response[<span class="string">&quot;output&quot;</span>])</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            error_msg = <span class="string">&quot;抱歉，我暂时无法处理这个问题，需要人工介入。&quot;</span></span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&quot;智能客服:&quot;</span>, error_msg, <span class="built_in">str</span>(e))</span><br><span class="line">            <span class="comment"># 也保存错误回复到历史，避免后续混乱</span></span><br><span class="line">            chat_history.add_user_message(user_input)</span><br><span class="line">            chat_history.add_ai_message(error_msg)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h3 id="多智能体（LangGraph）"><a href="https://github.com/HengLine/langchain-demo/blob/main/hybrid/hybrid_langgraph_multi_agent.py">多智能体（LangGraph）</a></h3>
<p>将单体客服系统<strong>拆分为多个专业智能体（Agents）</strong>，并通过 <strong>LangGraph</strong> 实现协作控制流，能显著提升系统的<strong>模块化、可维护性和推理能力</strong>。</p>
<p>本智能体不支持上下文理解，更多代码和使用方式，参照 <a href="https://github.com/HengLine/langchain-demo/blob/main/hybrid/hybrid_langgraph_summarized_multi_agent.py">GitHub</a>（自动摘要记忆，支持多轮对话，上下文理解）</p>
<p>多智能体 + LangGraph 协作流程图：</p>
<img src= "/img/20241215205335173426721579192.webp" data-lazy-src="/imgs/ai/pengline-converted-image.webp" alt="pengline-converted-image" style="zoom:33%;" />
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 1. 初始化数据库 &amp; 知识库</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line">DB_PATH = <span class="string">&quot;../data/customer_service.db&quot;</span></span><br><span class="line">KNOWLEDGE_DIR = <span class="string">&quot;knowledge_base&quot;</span></span><br><span class="line">VECTOR_STORE_PATH = <span class="string">&quot;../data/vectorstore&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_database</span>():</span><br><span class="line">    <span class="comment"># 此处省略（详细实现可参照GitHub 代码）</span></span><br><span class="line">    conn.commit(); conn.close()</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_rag</span>():</span><br><span class="line">	<span class="comment"># 此处省略（详细实现可参照GitHub 代码）</span></span><br><span class="line">    <span class="keyword">return</span> vs</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 2. 定义状态图结构</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">AgentState</span>(<span class="title class_ inherited__">TypedDict</span>):</span><br><span class="line">    messages: Annotated[<span class="built_in">list</span>, add_messages]</span><br><span class="line">    <span class="built_in">next</span>: <span class="built_in">str</span>  <span class="comment"># 下一步执行的 agent</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 3. 定义各智能体</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line">llm = ChatOllama(base_url=<span class="string">&quot;http://localhost:11434&quot;</span>, model=<span class="string">&quot;qwen3:8b&quot;</span>, temperature=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- Router Agent ---</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">RouteQuery</span>(<span class="title class_ inherited__">BaseModel</span>):</span><br><span class="line">    datasource: <span class="type">Literal</span>[<span class="string">&quot;order_db&quot;</span>, <span class="string">&quot;knowledge_base&quot;</span>, <span class="string">&quot;general&quot;</span>] = Field(</span><br><span class="line">        ..., description=<span class="string">&quot;问题类型：order_db（订单/用户）、knowledge_base（政策/说明）、general（其他）&quot;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">router_agent</span>(<span class="params">state: AgentState</span>):</span><br><span class="line">    prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个路由智能体，请判断用户问题属于哪一类：\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;- order_db：涉及订单、发货、用户信息等\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;- knowledge_base：涉及退货、产品说明、FAQ等\n&quot;</span></span><br><span class="line">                   <span class="string">&quot;- general：闲聊、无法分类的问题&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line">    router_llm = llm.with_structured_output(RouteQuery)</span><br><span class="line">    response = router_llm.invoke(prompt.format_messages(<span class="built_in">input</span>=state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;next&quot;</span>: response.datasource&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- DB Agent ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">db_agent</span>(<span class="params">state: AgentState</span>):</span><br><span class="line">    db = SQLDatabase.from_uri(<span class="string">f&quot;sqlite:///<span class="subst">&#123;DB_PATH&#125;</span>&quot;</span>)</span><br><span class="line">    agent = create_sql_agent(</span><br><span class="line">        llm=llm,</span><br><span class="line">        db=db,</span><br><span class="line">        agent_type=<span class="string">&quot;openai-tools&quot;</span>,  <span class="comment"># LangChain 会自动适配 Ollama 的 function calling</span></span><br><span class="line">        handle_parsing_errors=<span class="literal">True</span></span><br><span class="line">    )</span><br><span class="line">    last_msg = state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        result = agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: last_msg&#125;)</span><br><span class="line">        answer = result[<span class="string">&quot;output&quot;</span>]</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        answer = <span class="string">f&quot;数据库查询失败：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [AIMessage(content=answer)]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- RAG Agent ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">rag_agent</span>(<span class="params">state: AgentState</span>):</span><br><span class="line">    vectorstore = init_rag()</span><br><span class="line">    retriever = vectorstore.as_retriever(k=<span class="number">3</span>)</span><br><span class="line">    query = state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content</span><br><span class="line">    docs = retriever.invoke(query)</span><br><span class="line">    context = <span class="string">&quot;\n\n&quot;</span>.join([d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> context.strip():</span><br><span class="line">        <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [AIMessage(content=<span class="string">&quot;知识库中未找到相关信息。&quot;</span>)]&#125;</span><br><span class="line">    prompt = <span class="string">f&quot;你是客服，请根据以下资料回答：\n<span class="subst">&#123;context&#125;</span>\n\n问题：<span class="subst">&#123;query&#125;</span>\n回答：&quot;</span></span><br><span class="line">    response = llm.invoke(prompt)</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [AIMessage(content=response.content)]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- General Agent ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">general_agent</span>(<span class="params">state: AgentState</span>):</span><br><span class="line">    prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个友好客服，但无法访问订单或知识库。请礼貌回应。&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line">    response = llm.invoke(prompt.format_messages(<span class="built_in">input</span>=state[<span class="string">&quot;messages&quot;</span>][-<span class="number">1</span>].content))</span><br><span class="line">    <span class="keyword">return</span> &#123;<span class="string">&quot;messages&quot;</span>: [AIMessage(content=response.content)]&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 4. 构建 LangGraph 工作流</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">route_to_agent</span>(<span class="params">state: AgentState</span>) -&gt; <span class="type">Literal</span>[<span class="string">&quot;db_agent&quot;</span>, <span class="string">&quot;rag_agent&quot;</span>, <span class="string">&quot;general_agent&quot;</span>]:</span><br><span class="line">    <span class="keyword">return</span> state[<span class="string">&quot;next&quot;</span>]</span><br><span class="line"></span><br><span class="line">graph_builder = StateGraph(AgentState)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;router&quot;</span>, router_agent)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;db_agent&quot;</span>, db_agent)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;rag_agent&quot;</span>, rag_agent)</span><br><span class="line">graph_builder.add_node(<span class="string">&quot;general_agent&quot;</span>, general_agent)</span><br><span class="line"></span><br><span class="line">graph_builder.add_conditional_edges(</span><br><span class="line">    <span class="string">&quot;router&quot;</span>,</span><br><span class="line">    route_to_agent,</span><br><span class="line">    &#123;<span class="string">&quot;order_db&quot;</span>: <span class="string">&quot;db_agent&quot;</span>, <span class="string">&quot;knowledge_base&quot;</span>: <span class="string">&quot;rag_agent&quot;</span>, <span class="string">&quot;general&quot;</span>: <span class="string">&quot;general_agent&quot;</span>&#125;</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;db_agent&quot;</span>, END)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;rag_agent&quot;</span>, END)</span><br><span class="line">graph_builder.add_edge(<span class="string">&quot;general_agent&quot;</span>, END)</span><br><span class="line"></span><br><span class="line">graph_builder.set_entry_point(<span class="string">&quot;router&quot;</span>)</span><br><span class="line">app = graph_builder.<span class="built_in">compile</span>()</span><br></pre></td></tr></table></figure>
<h3 id="多智能体（Chain）"><a href="https://github.com/HengLine/langchain-demo/blob/main/hybrid/hybrid_chain_multi_agent.py">多智能体（Chain）</a></h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 1. 初始化 &amp; 环境</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line">DB_PATH = <span class="string">&quot;../data/customer_service.db&quot;</span></span><br><span class="line">KNOWLEDGE_DIR = <span class="string">&quot;knowledge_base&quot;</span></span><br><span class="line">VECTOR_STORE_PATH = <span class="string">&quot;../data/vectorstore&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 加载 .env 文件中的环境变量</span></span><br><span class="line">load_dotenv()</span><br><span class="line"></span><br><span class="line"><span class="comment"># 全局 LLM（用于路由 + General + RAG 生成）</span></span><br><span class="line">llm = ChatTongyi(</span><br><span class="line">    model=os.getenv(<span class="string">&quot;MODEL_NAME&quot;</span>, <span class="string">&quot;qwen-turbo&quot;</span>), </span><br><span class="line">    streaming=<span class="literal">True</span>,</span><br><span class="line">    model_kwargs=&#123;<span class="string">&quot;temperature&quot;</span>: <span class="number">0</span>&#125;,</span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 2. 初始化数据库</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_database</span>():</span><br><span class="line">    <span class="comment"># 此处省略（详细实现可参照GitHub 代码）</span></span><br><span class="line">    conn.commit(); conn.close()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 3. 初始化 RAG（Qwen Embedding）</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">init_rag</span>():</span><br><span class="line">    <span class="comment"># 此处省略（详细实现可参照GitHub 代码）</span></span><br><span class="line">    <span class="keyword">return</span> vs.as_retriever(k=<span class="number">3</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 4. 子系统实现（封装为 Runnable）</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># --- 路由 Chain ---</span></span><br><span class="line">router_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个分类器，请严格输出以下三者之一：order_db, knowledge_base, general\n&quot;</span></span><br><span class="line">               <span class="string">&quot;规则：\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 涉及订单、用户、发货 → order_db\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 涉及退货、政策、说明书 → knowledge_base\n&quot;</span></span><br><span class="line">               <span class="string">&quot;- 其他 → general&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;问题：&#123;input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">router_chain = router_prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- DB Agent（封装为 Runnable）---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_db_response</span>(<span class="params">query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    db = SQLDatabase.from_uri(<span class="string">f&quot;sqlite:///<span class="subst">&#123;DB_PATH&#125;</span>&quot;</span>)</span><br><span class="line">    agent = create_sql_agent(llm=llm, db=db, agent_type=<span class="string">&quot;openai-tools&quot;</span>, handle_parsing_errors=<span class="literal">True</span>, verbose=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        <span class="keyword">return</span> agent.invoke(&#123;<span class="string">&quot;input&quot;</span>: query&#125;)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="keyword">return</span> <span class="string">f&quot;数据库查询失败：<span class="subst">&#123;<span class="built_in">str</span>(e)&#125;</span>&quot;</span></span><br><span class="line"></span><br><span class="line">db_runnable = RunnableLambda(get_db_response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- RAG Chain ---</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_rag_response</span>(<span class="params">query: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    retriever = init_rag()</span><br><span class="line">    docs = retriever.invoke(query)</span><br><span class="line">    context = <span class="string">&quot;\n\n&quot;</span>.join([d.page_content <span class="keyword">for</span> d <span class="keyword">in</span> docs])</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> context.strip():</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;知识库中未找到相关信息。&quot;</span></span><br><span class="line">    rag_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">        (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个智能客服，请根据以下资料简洁回答用户问题。&quot;</span>),</span><br><span class="line">        (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;资料：&#123;context&#125;\n\n问题：&#123;query&#125;&quot;</span>)</span><br><span class="line">    ])</span><br><span class="line">    chain = rag_prompt | llm | StrOutputParser()</span><br><span class="line">    <span class="keyword">return</span> chain.invoke(&#123;<span class="string">&quot;context&quot;</span>: context, <span class="string">&quot;query&quot;</span>: query&#125;)</span><br><span class="line"></span><br><span class="line">rag_runnable = RunnableLambda(get_rag_response)</span><br><span class="line"></span><br><span class="line"><span class="comment"># --- General Chain ---</span></span><br><span class="line">general_prompt = ChatPromptTemplate.from_messages([</span><br><span class="line">    (<span class="string">&quot;system&quot;</span>, <span class="string">&quot;你是一个友好但功能有限的客服，无法访问订单或知识库。请礼貌回应用户的问题。&quot;</span>),</span><br><span class="line">    (<span class="string">&quot;human&quot;</span>, <span class="string">&quot;&#123;input&#125;&quot;</span>)</span><br><span class="line">])</span><br><span class="line">general_chain = general_prompt | llm | StrOutputParser()</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="comment"># 5. 主执行逻辑（Chain 风格路由）</span></span><br><span class="line"><span class="comment"># ----------------------------</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">route_and_run</span>(<span class="params">user_input: <span class="built_in">str</span></span>) -&gt; <span class="built_in">str</span>:</span><br><span class="line">    <span class="comment"># Step 1: 路由</span></span><br><span class="line">    route = router_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_input&#125;).strip()</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&quot;[路由结果: <span class="subst">&#123;route&#125;</span>]&quot;</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Step 2: 根据路由调用对应子系统</span></span><br><span class="line">    <span class="keyword">if</span> route == <span class="string">&quot;order_db&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> db_runnable.invoke(user_input)</span><br><span class="line">    <span class="keyword">elif</span> route == <span class="string">&quot;knowledge_base&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> rag_runnable.invoke(user_input)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> general_chain.invoke(&#123;<span class="string">&quot;input&quot;</span>: user_input&#125;)</span><br></pre></td></tr></table></figure>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="https://pengline.github.io">余一叶知秋尽</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="https://pengline.github.io/2025/11/0c17e5dc04ae4994b411db081a7c82d6/">https://pengline.github.io/2025/11/0c17e5dc04ae4994b411db081a7c82d6/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="https://pengline.github.io" target="_blank">余一叶知秋尽</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/LangChain%E6%A1%86%E6%9E%B6/">LangChain框架</a><a class="post-meta__tags" href="/tags/LangChain%E7%8A%B6%E6%80%81%E8%AE%B0%E5%BF%86/">LangChain状态记忆</a><a class="post-meta__tags" href="/tags/LangChain%E6%99%BA%E8%83%BD%E5%86%B3%E7%AD%96/">LangChain智能决策</a><a class="post-meta__tags" href="/tags/LangChain%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B/">LangChain提示工程</a><a class="post-meta__tags" href="/tags/LangChain%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8/">LangChain工具调用</a><a class="post-meta__tags" href="/tags/LangChain%E6%A8%A1%E5%9E%8B%E7%AE%A1%E7%90%86/">LangChain模型管理</a><a class="post-meta__tags" href="/tags/LangChain%E9%93%BE/">LangChain链</a></div><div class="post-share"><div class="social-share" data-image="/img/essay/small162627wjXnR1759047987.webp" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2025/11/1b5dccbef2e144a8964580cb70ed0227/" title="MySQL 自增主键的原理和执行流程"><img class="cover" src= "/img/20241215205335173426721579192.webp" data-lazy-src="/img/essay/1638860420693163886042042.webp" onerror="onerror=null;src='/img/k3zssqvjw2d.jpg'" alt="cover of previous post"><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">MySQL 自增主键的原理和执行流程</div></div><div class="info-2"><div class="info-item-1">自增主键是 MySQL 中特殊的列属性，用于自动生成唯一的递增值。本文从原理机制、使用方式等方面详细说明。</div></div></div></a><a class="pagination-related" href="/2025/10/0194020a663c408fb500dd7532349519/" title="剧本分镜智能体架构设计与实现细节"><img class="cover" src= "/img/20241215205335173426721579192.webp" data-lazy-src="/img/essay/1634204644701163420464439.webp" onerror="onerror=null;src='/img/k3zssqvjw2d.jpg'" alt="cover of next post"><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">剧本分镜智能体架构设计与实现细节</div></div><div class="info-2"><div class="info-item-1">该工具将自然语言剧本自动拆分为多个N秒长度的短视频片段脚本，以适用于 AI 视频生成模型，可直接用于“文生视频”。</div></div></div></a></nav><hr class="custom-hr"/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="giscus-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%AE%A1%E7%90%86%EF%BC%88LLM%EF%BC%89"><span class="toc-number">1.</span> <span class="toc-text">模型管理（LLM）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Ollama"><span class="toc-number">1.1.</span> <span class="toc-text">Ollama</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#OpenAI"><span class="toc-number">1.2.</span> <span class="toc-text">OpenAI</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%83%E9%97%AE"><span class="toc-number">1.3.</span> <span class="toc-text">千问</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%EF%BC%88Prompt"><span class="toc-number">2.</span> <span class="toc-text">提示工程（Prompt)</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%93%BE%E5%BC%8F%E7%BC%96%E6%8E%92%EF%BC%88Chain%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">链式编排（Chain）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%99%BA%E8%83%BD%E5%86%B3%E7%AD%96%EF%BC%88Agents%EF%BC%89"><span class="toc-number">4.</span> <span class="toc-text">智能决策（Agents）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B7%A5%E5%85%B7%E8%B0%83%E7%94%A8%EF%BC%88Tool%EF%BC%89"><span class="toc-number">5.</span> <span class="toc-text">工具调用（Tool）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E8%AE%B0%E5%BF%86%EF%BC%88Memory%EF%BC%89"><span class="toc-number">6.</span> <span class="toc-text">状态记忆（Memory）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80%E8%AE%B0%E5%BF%86"><span class="toc-number">6.1.</span> <span class="toc-text">基础记忆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%AA%97%E5%8F%A3%E8%AE%B0%E5%BF%86%EF%BC%88%E9%95%BF%E5%AF%B9%E8%AF%9D%EF%BC%89"><span class="toc-number">6.2.</span> <span class="toc-text">窗口记忆（长对话）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%91%98%E8%A6%81%E8%AE%B0%E5%BF%86%EF%BC%88%E8%B6%85%E9%95%BF%E5%AF%B9%E8%AF%9D%EF%BC%89"><span class="toc-number">6.3.</span> <span class="toc-text">摘要记忆（超长对话）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BD%93%E8%AE%B0%E5%BF%86"><span class="toc-number">6.4.</span> <span class="toc-text">实体记忆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%90%91%E9%87%8F%E8%AE%B0%E5%BF%86%EF%BC%88%E7%9F%A5%E8%AF%86%E5%BA%93%EF%BC%89"><span class="toc-number">6.5.</span> <span class="toc-text">向量记忆（知识库）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Agent-%E5%B7%A5%E5%85%B7"><span class="toc-number">6.6.</span> <span class="toc-text">Agent 工具</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%8C%81%E4%B9%85%E5%8C%96%E8%AE%B0%E5%BF%86"><span class="toc-number">6.7.</span> <span class="toc-text">持久化记忆</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%AB%98%E7%BA%A7%E6%8A%80%E5%B7%A7"><span class="toc-number">6.8.</span> <span class="toc-text">高级技巧</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E7%90%86%E8%A7%A3"><span class="toc-number">6.9.</span> <span class="toc-text">上下文理解</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8A%B6%E6%80%81%E5%9B%BE%EF%BC%88LangGraph%EF%BC%89"><span class="toc-number">7.</span> <span class="toc-text">状态图（LangGraph）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E7%A1%80-Demo"><span class="toc-number">8.</span> <span class="toc-text">基础 Demo</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%99%BA%E8%83%BD%E5%AE%A2%E6%9C%8D%E6%9C%BA%E5%99%A8%E4%BA%BA"><span class="toc-number">9.</span> <span class="toc-text">智能客服机器人</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%8D%95%E6%99%BA%E8%83%BD%E4%BD%93"><span class="toc-number">9.1.</span> <span class="toc-text">单智能体</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%EF%BC%88LangGraph%EF%BC%89"><span class="toc-number">9.2.</span> <span class="toc-text">多智能体（LangGraph）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%EF%BC%88Chain%EF%BC%89"><span class="toc-number">9.3.</span> <span class="toc-text">多智能体（Chain）</span></a></li></ol></li></ol></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 By 余一叶知秋尽</span><span class="framework-info"><span>框架 </span><a href="https://hexo.io">Hexo 7.3.0</a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.4.3</a></span></div><div class="footer_custom_text"><p><a style="margin-inline:5px"target="_blank"href="https://github.com/"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="https://img.shields.io/badge/Hosted-Github-brightgreen?style=flat&logo=GitHub"title="本站项目由Gtihub托管"></a><a style="margin-inline:5px"target="_blank"href="https://hexo.io/"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="https://img.shields.io/badge/Frame-Hexo-blue?style=flat&logo=hexo"title="博客框架为Hexo"></a><a style="margin-inline:5px"target="_blank"href="https://butterfly.js.org/"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="https://img.shields.io/badge/Theme-Butterfly-6513df?logoColor=white&style=flat&logo=buefy"title="主题采用butterfly"></a><a style="margin-inline:5px"target="_blank"href="https://giscus.app/zh-CN/"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="https://img.shields.io/badge/Comment-Giscus-2873df?logoColor=white&style=flat&logo=git"title="评论系统为Giscus"></a><a style="margin-inline:5px"target="_blank"href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img src= "/img/20241215205335173426721579192.webp" data-lazy-src="https://img.shields.io/badge/Copyright-BY--NC--SA%204.0-d42328?style=flat&logo=Claris"title="本站采用知识共享署名-非商业性使用-相同方式共享4.0国际许可协议进行许可"></a></p></div><script src="https://unpkg.com/mermaid@11.5.0/dist/mermaid.min.js"></script><script>if (window.mermaid) {
  mermaid.initialize({
    startOnLoad: true,
    theme: '[object Object]',
    securityLevel: 'loose',
    flowchart: { useMaxWidth: true, htmlLabels: true }
  });
}</script></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><a class="icon-V hidden" onclick="switchNightMode()" title="日间和夜间模式切换"><svg width="25" height="25" viewBox="0 0 1024 1024"><use id="modeicon" xlink:href="#icon-moon"></use></svg></a><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="前往评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox/fancybox.umd.min.js"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><div class="js-pjax"><script>(() => {
  const runMermaid = ele => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    ele.forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = `%%{init:{ 'theme':'${theme}'}}%%\n`
      const mermaidID = `mermaid-${index}`
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)
      const renderMermaid = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      // mermaid v9 and v10 compatibility
      typeof renderFn === 'string' ? renderMermaid(renderFn) : renderFn.then(({ svg }) => renderMermaid(svg))
    })
  }

  const codeToMermaid = () => {
    const codeMermaidEle = document.querySelectorAll('pre > code.mermaid')
    if (codeMermaidEle.length === 0) return

    codeMermaidEle.forEach(ele => {
      const preEle = document.createElement('pre')
      preEle.className = 'mermaid-src'
      preEle.hidden = true
      preEle.textContent = ele.textContent
      const newEle = document.createElement('div')
      newEle.className = 'mermaid-wrap'
      newEle.appendChild(preEle)
      ele.parentNode.replaceWith(newEle)
    })
  }

  const loadMermaid = () => {
    if (true) codeToMermaid()
    const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
    if ($mermaid.length === 0) return

    const runMermaidFn = () => runMermaid($mermaid)
    btf.addGlobalFn('themeChange', runMermaidFn, 'mermaid')
    window.loadMermaid ? runMermaidFn() : btf.getScript('https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.min.js').then(runMermaidFn)
  }

  btf.addGlobalFn('encrypt', loadMermaid, 'mermaid')
  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>(() => {
  const isShuoshuo = GLOBAL_CONFIG_SITE.pageType === 'shuoshuo'
  const option = null

  const getGiscusTheme = theme => theme === 'dark' ? 'dark' : 'light'

  const createScriptElement = config => {
    const ele = document.createElement('script')
    Object.entries(config).forEach(([key, value]) => {
      ele.setAttribute(key, value)
    })
    return ele
  }

  const loadGiscus = (el = document, key) => {
    const mappingConfig = isShuoshuo
      ? { 'data-mapping': 'specific', 'data-term': key }
      : { 'data-mapping': (option && option['data-mapping']) || 'pathname' }

    const giscusConfig = {
      src: 'https://giscus.app/client.js',
      'data-repo': 'pengline/pengline.github.io',
      'data-repo-id': 'R_kgDOPqG50w',
      'data-category-id': 'DIC_kwDOPqG5084Cu_K9',
      'data-theme': getGiscusTheme(document.documentElement.getAttribute('data-theme')),
      'data-reactions-enabled': '1',
      crossorigin: 'anonymous',
      'data-lang': 'zh-CN',
      'data-input-position': 'top',
      async: true,
      ...option,
      ...mappingConfig
    }

    const scriptElement = createScriptElement(giscusConfig)

    el.querySelector('#giscus-wrap').appendChild(scriptElement)

    if (isShuoshuo) {
      window.shuoshuoComment.destroyGiscus = () => {
        if (el.children.length) {
          el.innerHTML = ''
          el.classList.add('no-comment')
        }
      }
    }
  }

  const changeGiscusTheme = theme => {
    const iframe = document.querySelector('#giscus-wrap iframe')
    if (iframe) {
      const message = {
        giscus: {
          setConfig: {
            theme: getGiscusTheme(theme),
            lang: 'zh-CN'
          }
        }
      }
      iframe.contentWindow.postMessage(message, 'https://giscus.app')
    }
  }

  btf.addGlobalFn('themeChange', changeGiscusTheme, 'giscus')

  if (isShuoshuo) {
    'Giscus' === 'Giscus'
      ? window.shuoshuoComment = { loadComment: loadGiscus }
      : window.loadOtherComment = loadGiscus
    return
  }

  if ('Giscus' === 'Giscus' || !false) {
    if (false) btf.loadComment(document.getElementById('giscus-wrap'), loadGiscus)
    else loadGiscus()
  } else {
    window.loadOtherComment = loadGiscus
  }
})()</script></div><script src="/js/custom/sun_moon.js" async></script><script id="canvas_nest" defer="defer" color="0,0,255" opacity="0.7" zIndex="-1" count="99" mobile="true" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc/dist/canvas-nest.min.js"></script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div><hr/><div id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="/js/search/local-search.js"></script></div></div></body></html>